2）What do they do? How do they do it?
The code uses the backpropagation algorithm to train the artificial neural network. Its first step is to input the training set and then forward propagation. From the input layer to the hidden layer, calculate the input weighted sum of the neurons, the output of the neurons. From the hidden layer to the input layer, the value of the output layer neurons is calculated, and the process of forward propagation ends. At this time, the output value is far from the actual value. The error is then backpropagated to calculate the total error. Then, the weight update from the hidden layer to the output layer, and the weight update from the hidden layer to the hidden layer is performed. Finally, the updated weights are recalculated and iteratively iterated.
3）Clear and not clear.
I know that its goal is to make the output as close as possible to the original output. The backpropagation algorithm is mainly iteratively looped by two links (excitation propagation, weight update) until the response of the network to the input reaches a predetermined target range. The backpropagation algorithm is calculated based on chain rules.
What I do not understand is the derivation process of the backpropagation algorithm，, the specific use, and the incomprehension of why input and output are the same.
